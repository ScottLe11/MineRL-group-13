{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50932e4e",
   "metadata": {},
   "source": [
    "# MAC Installation Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb1ac69e-6628-47e9-a25f-1c65338facf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3561790024.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[10], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    export JAVA_HOME=$(/usr/libexec/java_home -v 1.8)\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#1. Install Java JDK 8 (Required for MineRL)\n",
    "!brew tap AdoptOpenJDK/openjdk\n",
    "!brew install --cask adoptopenjdk8 \n",
    "export JAVA_HOME=$(/usr/libexec/java_home -v 1.8)\n",
    "\n",
    "#2. Create environment\n",
    "conda create --platform osx-64 -n minerl-env python=3.9 -y\n",
    "conda activate minerl-env\n",
    "\n",
    "#3. Install dependencies\n",
    "git clone [https://github.com/minerllabs/minerl.git](https://github.com/minerllabs/minerl.git)\n",
    "sed -i .bak 's/3\\.2\\.1/3.3.1/' ./minerl/scripts/mcp_patch.diff\n",
    "cd minerl\n",
    "pip install .\n",
    "\n",
    "#4. Patch Launch Scripts for Mac\n",
    "sed -i .bak s/'java -Xmx\\$maxMem'/'java -Xmx\\$maxMem -XstartOnFirstThread'/ ./minerl/MCP-Reborn/launchClient.sh\n",
    "sed -i .bak /'GLFW.glfwSetWindowIcon(this.handle, buffer);'/d ./minerl/MCP-Reborn/src/main/java/net/minecraft/client/MainWindow.java\n",
    "sed -i .bak '125,136s/^/\\/\\//' ./minerl/MCP-Reborn/src/main/java/net/minecraft/client/MainWindow.java\n",
    "\n",
    "#5. Build and Move JARs\n",
    "cd minerl/MCP-Reborn && ./gradlew clean build shadowJar \n",
    "cd ../../../\n",
    "cp -rf ./minerl/minerl/MCP-Reborn/* TARGET_DIR=$(python -c \"import site; print(site.getsitepackages()[0])\")/minerl/MCP-Reborn/\n",
    "cp -rf ./minerl/minerl/MCP-Reborn/* \"$TARGET_DIR\"\n",
    "\n",
    "#6. Install Python reqs \n",
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea94239-0620-47b1-96a3-e33dbfaf64a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile config.yaml\n",
    "bc:\n",
    "  data_path: \"bc_expert_data.npz\"\n",
    "  learning_rate: 0.0003\n",
    "  batch_size: 64\n",
    "  gradient_clip: 1.0\n",
    "  q_regularization: 0.01\n",
    "  prefill_replay_buffer: false\n",
    "  lambda_supervised: 1.0\n",
    "  lambda_td: 1.0\n",
    "  lambda_margin: 1.0\n",
    "  lambda_l2: 0.00001\n",
    "  margin: 0.8\n",
    "environment:\n",
    "  name: \"MineRLcustom_treechop-v0\"\n",
    "  episode_seconds: 60\n",
    "  frame_shape: [84, 84]\n",
    "  frame_stack: 4\n",
    "  curriculum:\n",
    "    spawn_type: \"random\"\n",
    "    with_logs: 5\n",
    "    with_axe: false\n",
    "network:\n",
    "  input_channels: 4\n",
    "  architecture: \"medium\"\n",
    "  attention: \"cbam\"\n",
    "  use_scalar_network: true\n",
    "  scalar_hidden_dim: 64\n",
    "  scalar_output_dim: 64\n",
    "action_space:\n",
    "  preset: \"custom\"\n",
    "  enabled_actions: [0, 1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 15, 17, 19, 20, 21, 23, 24]\n",
    "dqn:\n",
    "  num_actions: null\n",
    "  learning_rate: 0.0001\n",
    "  gamma: 0.99\n",
    "  batch_size: 64\n",
    "  gradient_clip: 5\n",
    "  replay_buffer:\n",
    "    capacity: 40000\n",
    "    min_size: 4000\n",
    "  exploration:\n",
    "    epsilon_start: 0.95\n",
    "    epsilon_end: 0.05\n",
    "    epsilon_decay_steps: 40000\n",
    "  target_update:\n",
    "    method: \"hard\"\n",
    "    tau: 0.005\n",
    "    hard_update_freq: 400\n",
    "  prioritized_replay:\n",
    "    enabled: true\n",
    "    alpha: 0.6\n",
    "    beta_start: 0.4\n",
    "    beta_end: 1.0\n",
    "training:\n",
    "  num_episodes: 4000\n",
    "  train_freq: 5\n",
    "  log_freq: 5\n",
    "  save_freq: 50\n",
    "  eval_freq: 50\n",
    "  eval_episodes: 5\n",
    "  grad_cam_freq: 50\n",
    "  env_recreation_interval: 25\n",
    "  checkpoint_dir: \"checkpoints\"\n",
    "  log_dir: \"runs\"\n",
    "  grad_cam_checkpoint_path: \"checkpoints/best_model_dqn.pt\"\n",
    "  video_recording:\n",
    "    enabled: false\n",
    "    save_dir: \"videos\"\n",
    "    fps: 10\n",
    "ppo:\n",
    "  learning_rate: 0.0001\n",
    "  gamma: 0.99\n",
    "  gae_lambda: 0.95\n",
    "  clip_epsilon: 0.2\n",
    "  entropy_coef: 0.02\n",
    "  value_coef: 0.5\n",
    "  max_grad_norm: 0.5\n",
    "  n_steps: 1024\n",
    "  n_epochs: 6\n",
    "  batch_size: 64\n",
    "algorithm: \"ppo\"\n",
    "rewards:\n",
    "  wood_value: 5.0\n",
    "  step_penalty: -0.001\n",
    "  axe_reward: 15.0\n",
    "  plank_reward: 20.0\n",
    "  stick_reward: 10.0\n",
    "  waste_penalty: -4.0\n",
    "device: \"auto\"\n",
    "seed: null\n",
    "grad_cam:\n",
    "  attack_action_index: 6\n",
    "  output_filename: \"grad_cam_visualization.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50849591-eeee-42ba-b81f-cf0744c7ebbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file already exists.\n"
     ]
    }
   ],
   "source": [
    "# Download the Pre-trained Model\n",
    "import os\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install gdown -q\n",
    "\n",
    "import gdown\n",
    "\n",
    "file_id = '1pjkPA4y1_P7QsrSCGhXzmEnBJ4gvliEm'\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "output = 'checkpoint_ppo_ep3000.pt'\n",
    "\n",
    "if not os.path.exists(output):\n",
    "    print(f\"Downloading model from Google Drive...\")\n",
    "    try:\n",
    "        gdown.download(url, output, quiet=False)\n",
    "        print(\"\\nDownload complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading: {e}\")\n",
    "else:\n",
    "    print(\"Model file already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cda5f072-3873-483c-acbb-69ae7655db33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Custom environment 'MineRLcustom_treechop-v0' registered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandon/Documents/envs/minerl-env/lib/python3.9/site-packages/gym/envs/registration.py:595: UserWarning: \u001b[33mWARN: Overriding environment MineRLcustom_treechop-v0\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {id}\")\n"
     ]
    }
   ],
   "source": [
    "# [Cell] - Define and Register Custom Environment\n",
    "import gym\n",
    "from gym.envs.registration import register\n",
    "from minerl.herobraine.env_specs.human_controls import HumanControlEnvSpec\n",
    "from minerl.herobraine.hero import handlers\n",
    "from minerl.herobraine.hero import mc as MC\n",
    "\n",
    "# 1. Define Base Treechop Spec\n",
    "class Treechop(HumanControlEnvSpec):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if 'name' not in kwargs: kwargs['name'] = 'MineRLTreechop-v0'\n",
    "        if 'max_episode_steps' not in kwargs: kwargs['max_episode_steps'] = 8000\n",
    "        super().__init__(*args, reward_threshold=64.0, **kwargs)\n",
    "        \n",
    "    def create_rewardables(self):\n",
    "        return [handlers.RewardForCollectingItems([dict(type=\"log\", amount=1, reward=1.0)])]\n",
    "    \n",
    "    def create_agent_start(self):\n",
    "        return super().create_agent_start() + [handlers.SimpleInventoryAgentStart([dict(type=\"oak_log\", quantity=3)])]\n",
    "\n",
    "    def create_agent_handlers(self):\n",
    "        return [handlers.AgentQuitFromPossessingItem([dict(type=\"log\", amount=64)])]\n",
    "    \n",
    "    def create_actionables(self):\n",
    "        acts = [handlers.KeybasedCommandAction(k, v) for k, v in MC.KEYMAP.items()]\n",
    "        acts.append(handlers.CameraAction())\n",
    "        return acts\n",
    "\n",
    "    def create_server_world_generators(self):\n",
    "        opts = \"\"\"{\"coordinateScale\":684.412,\"heightScale\":684.412,\"lowerLimitScale\":512.0,\"upperLimitScale\":512.0,\"depthNoiseScaleX\":200.0,\"depthNoiseScaleZ\":200.0,\"depthNoiseScaleExponent\":0.5,\"mainNoiseScaleX\":80.0,\"mainNoiseScaleY\":160.0,\"mainNoiseScaleZ\":80.0,\"baseSize\":8.5,\"stretchY\":12.0,\"biomeDepthWeight\":0.0,\"biomeDepthOffset\":0.0,\"biomeScaleWeight\":0.0,\"biomeScaleOffset\":0.0,\"seaLevel\":1,\"useCaves\":false,\"useDungeons\":false,\"dungeonChance\":8,\"useStrongholds\":false,\"useVillages\":false,\"useMineShafts\":false,\"useTemples\":false,\"useMonuments\":false,\"useMansions\":false,\"useRavines\":false,\"useWaterLakes\":false,\"waterLakeChance\":4,\"useLavaLakes\":false,\"lavaLakeChance\":80,\"useLavaOceans\":false,\"fixedBiome\":11,\"biomeSize\":4,\"riverSize\":1,\"dirtSize\":33,\"dirtCount\":10,\"dirtMinHeight\":0,\"dirtMaxHeight\":256,\"gravelSize\":33,\"gravelCount\":8,\"gravelMinHeight\":0,\"gravelMaxHeight\":256,\"graniteSize\":33,\"graniteCount\":10,\"graniteMinHeight\":0,\"graniteMaxHeight\":80,\"dioriteSize\":33,\"dioriteCount\":10,\"dioriteMinHeight\":0,\"dioriteMaxHeight\":80,\"andesiteSize\":33,\"andesiteCount\":10,\"andesiteMinHeight\":0,\"andesiteMaxHeight\":80,\"coalSize\":17,\"coalCount\":20,\"coalMinHeight\":0,\"coalMaxHeight\":128,\"ironSize\":9,\"ironCount\":20,\"ironMinHeight\":0,\"ironMaxHeight\":64,\"goldSize\":9,\"goldCount\":2,\"goldMinHeight\":0,\"goldMaxHeight\":32,\"redstoneSize\":8,\"redstoneCount\":8,\"redstoneMinHeight\":0,\"redstoneMaxHeight\":16,\"diamondSize\":8,\"diamondCount\":1,\"diamondMinHeight\":0,\"diamondMaxHeight\":16,\"lapisSize\":7,\"lapisCount\":1,\"lapisCenterHeight\":16,\"lapisSpread\":16}\"\"\"\n",
    "        return [handlers.DefaultWorldGenerator(force_reset=\"true\", generator_options=opts)]\n",
    "\n",
    "    def create_server_quit_producers(self):\n",
    "        return [handlers.ServerQuitFromTimeUp(8000 * 50), handlers.ServerQuitWhenAnyAgentFinishes()]\n",
    "\n",
    "    def create_server_initial_conditions(self):\n",
    "        return [handlers.TimeInitialCondition(allow_passage_of_time=False), handlers.SpawningInitialCondition(allow_spawning=False)]\n",
    "\n",
    "    # --- MISSING METHODS ADDED HERE TO FIX CRASH ---\n",
    "    def create_server_decorators(self):\n",
    "        return []\n",
    "\n",
    "    def determine_success_from_rewards(self, rewards: list) -> bool:\n",
    "        return sum(rewards) >= self.reward_threshold\n",
    "    # -----------------------------------------------\n",
    "\n",
    "    def is_from_folder(self, folder): return folder == 'survivaltreechop'\n",
    "    def get_docstring(self): return \"\"\n",
    "\n",
    "# 2. Define Custom Configurable Environment\n",
    "class custom_treechop(Treechop):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        if 'name' not in kwargs: kwargs['name'] = 'MineRLcustom_treechop-v0'\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def create_agent_start(self):\n",
    "        with_logs = 5 \n",
    "        with_axe = False \n",
    "        \n",
    "        # Use grandparent method to skip Treechop's hardcoded inventory\n",
    "        base_handlers = HumanControlEnvSpec.create_agent_start(self)\n",
    "        \n",
    "        inventory = []\n",
    "        if with_logs > 0: inventory.append(dict(type=\"oak_log\", quantity=with_logs))\n",
    "        if with_axe: inventory.append(dict(type=\"wooden_axe\", quantity=1))\n",
    "        \n",
    "        if inventory: base_handlers.append(handlers.SimpleInventoryAgentStart(inventory))\n",
    "        base_handlers.append(handlers.AgentStartNear([dict(type=\"log\", distance=5)]))\n",
    "        return base_handlers\n",
    "\n",
    "# 3. Register the Environment\n",
    "def make_fist_treechop_env():\n",
    "    spec = custom_treechop(resolution=(640, 360))\n",
    "    return spec.make()\n",
    "\n",
    "try:\n",
    "    register(\n",
    "        id='MineRLcustom_treechop-v0',\n",
    "        entry_point=make_fist_treechop_env,\n",
    "        max_episode_steps=1510\n",
    "    )\n",
    "    print(\"✅ Custom environment 'MineRLcustom_treechop-v0' registered.\")\n",
    "except Exception as e:\n",
    "    # If already registered, we just print the error but continue\n",
    "    print(f\"Environment registration skipped: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0731b125-4493-4ffe-9808-6e68b71e14e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell] - Define Wrappers, Network, and Agent Class\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gym\n",
    "from collections import deque\n",
    "import cv2\n",
    "from gym import ActionWrapper\n",
    "from gym.spaces import Discrete\n",
    "\n",
    "# ==========================================\n",
    "# 1. WRAPPERS (hold_attack, reward, vision)\n",
    "# ==========================================\n",
    "\n",
    "class HoldAttackWrapper(gym.Wrapper):\n",
    "    \"\"\"Extends a single attack action into a held attack sequence.\"\"\"\n",
    "    def __init__(self, env, hold_steps=35, yaw_per_tick=0.0, fwd_jump_ticks=0,\n",
    "                 lock_aim=True, pass_through_move=False, gui_cooldown=4):\n",
    "        super().__init__(env)\n",
    "        self.hold_steps = hold_steps\n",
    "        self.yaw_per_tick = yaw_per_tick\n",
    "        self.fwd_jump_ticks = fwd_jump_ticks\n",
    "        self.lock_aim = lock_aim\n",
    "        self.pass_through_move = pass_through_move\n",
    "        self.gui_cooldown = gui_cooldown\n",
    "        self._attack_left = 0\n",
    "        self._gui_open = False\n",
    "        self._hold_block = 0\n",
    "        self._suppress = False\n",
    "\n",
    "    def set_hold_suppressed(self, flag=True):\n",
    "        self._suppress = bool(flag)\n",
    "        self._attack_left = 0\n",
    "        self._hold_block = self.gui_cooldown if flag else 0\n",
    "\n",
    "    def step(self, action):\n",
    "        if self._suppress: return self.env.step(action)\n",
    "        \n",
    "        # Simplified GUI detection\n",
    "        if action.get(\"inventory\", 0) == 1:\n",
    "            self._attack_left = 0\n",
    "            self._hold_block = self.gui_cooldown\n",
    "            return self.env.step(action)\n",
    "\n",
    "        if self._hold_block > 0: self._hold_block -= 1\n",
    "        \n",
    "        # Start holding attack\n",
    "        if self._hold_block == 0 and self._attack_left == 0 and action.get('attack', 0) == 1:\n",
    "            self._attack_left = self.hold_steps\n",
    "\n",
    "        # Continue holding attack\n",
    "        if self._attack_left > 0 and self._hold_block == 0:\n",
    "            action['attack'] = 1\n",
    "            if self.lock_aim: action['camera'] = np.array([0.0, 0.0], dtype=np.float32)\n",
    "            self._attack_left -= 1\n",
    "\n",
    "        return self.env.step(action)\n",
    "\n",
    "class StackAndProcessWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, shape=(84, 84)):\n",
    "        super().__init__(env)\n",
    "        self.shape = shape\n",
    "        self.frame_stack = deque(maxlen=4)\n",
    "        self.observation_space.spaces['pov'] = gym.spaces.Box(\n",
    "            low=0, high=255, shape=(4, shape[0], shape[1]), dtype=np.uint8)\n",
    "\n",
    "    def _preprocess(self, frame):\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        return cv2.resize(frame, self.shape, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    def _get_stacked_obs(self): return np.stack(self.frame_stack, axis=0)\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        f = self._preprocess(obs['pov'])\n",
    "        for _ in range(4): self.frame_stack.append(f)\n",
    "        obs['pov'] = self._get_stacked_obs()\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.frame_stack.append(self._preprocess(obs['pov']))\n",
    "        obs['pov'] = self._get_stacked_obs()\n",
    "        return obs, reward, done, info\n",
    "\n",
    "class ObservationWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, max_episode_steps=1200):\n",
    "        super().__init__(env)\n",
    "        self.max_episode_steps = max_episode_steps\n",
    "        self.current_episode_step = 0\n",
    "        self.yaw = 0.0; self.pitch = 0.0\n",
    "\n",
    "    def reset(self):\n",
    "        obs = self.env.reset()\n",
    "        self.current_episode_step = 0; self.yaw = 0.0; self.pitch = 0.0\n",
    "        return self._add_scalars(obs)\n",
    "\n",
    "    def step(self, action):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        self.current_episode_step += 1\n",
    "        return self._add_scalars(obs), reward, done, info\n",
    "\n",
    "    def _add_scalars(self, obs):\n",
    "        time_norm = max(0.0, (self.max_episode_steps - self.current_episode_step)/self.max_episode_steps)\n",
    "        extended_obs = dict(obs) if isinstance(obs, dict) else {'pov': obs}\n",
    "        \n",
    "        # Simplified scalar injection for demo purposes\n",
    "        extended_obs['time_left'] = np.array([time_norm], dtype=np.float32)\n",
    "        extended_obs['yaw'] = np.array([self.yaw/180.0], dtype=np.float32)\n",
    "        extended_obs['pitch'] = np.array([self.pitch/90.0], dtype=np.float32)\n",
    "        extended_obs['place_table_safe'] = np.array([1.0], dtype=np.float32)\n",
    "        \n",
    "        # Inventory Placeholders (requires parsing 'inventory' dict if available)\n",
    "        inv_keys = ['inv_logs', 'inv_planks', 'inv_sticks', 'inv_table', 'inv_axe']\n",
    "        for k in inv_keys: extended_obs[k] = np.array([0.0], dtype=np.float32)\n",
    "        \n",
    "        return extended_obs\n",
    "\n",
    "# ==========================================\n",
    "# 2. ACTIONS.PY (Simplified for Notebook)\n",
    "# ==========================================\n",
    "# In a real deployment, paste the full actions.py content in this Cell.\n",
    "# Here we implement the wrapper to map index -> action dict\n",
    "class ConfigurableActionWrapper(ActionWrapper):\n",
    "    def __init__(self, env, enabled_actions):\n",
    "        super().__init__(env)\n",
    "        self.enabled_actions = enabled_actions\n",
    "        self.action_space = Discrete(len(enabled_actions))\n",
    "        \n",
    "        # Define Primitives (Subset for demo)\n",
    "        self.primitives = [\n",
    "            {}, {'forward': 1}, {'back': 1}, {'right': 1}, {'left': 1}, \n",
    "            {'jump': 1, 'forward': 1}, {'attack': 1}, \n",
    "            # Camera (simplified)\n",
    "            {'camera': np.array([0, -7.5])}, {'camera': np.array([0, -11.25])}, \n",
    "            {'camera': np.array([0, 7.5])}, {'camera': np.array([0, 11.25])}, \n",
    "            {'camera': np.array([-3.0, 0])}, {'camera': np.array([3.0, 0])} \n",
    "        ]\n",
    "\n",
    "    def action(self, action_index):\n",
    "        # Map configured index to actual logic\n",
    "        # For this demo, we handle basic movement. \n",
    "        # Full mapping requires crafting logic from actions.py\n",
    "        if action_index < len(self.primitives):\n",
    "            act = self.env.action_space.no_op()\n",
    "            for k, v in self.primitives[action_index].items(): act[k] = v\n",
    "            return act\n",
    "        return self.env.action_space.no_op()\n",
    "\n",
    "# ==========================================\n",
    "# 3. NETWORK ARCHITECTURE (Attention, CNN, Policy)\n",
    "# ==========================================\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        max_pool = torch.max(x, dim=1, keepdim=True)[0]\n",
    "        avg_pool = torch.mean(x, dim=1, keepdim=True)\n",
    "        attention = self.sigmoid(self.conv(torch.cat([max_pool, avg_pool], dim=1)))\n",
    "        return x * attention\n",
    "\n",
    "class MediumCNN(nn.Module):\n",
    "    def __init__(self, input_channels=4):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 32, 8, 4), nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 4, 2), nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, 3, 1), nn.ReLU()\n",
    "        )\n",
    "        self.fc = nn.Sequential(nn.Linear(128*7*7, 512), nn.ReLU())\n",
    "        self._output_dim = 512\n",
    "    def forward(self, x):\n",
    "        if x.max() > 1.0: x = x.float() / 255.0\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class ScalarNetwork(nn.Module):\n",
    "    def __init__(self, num_scalars=9):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(num_scalars, 64), nn.ReLU(), nn.Linear(64, 64), nn.ReLU())\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class ActorCriticNetwork(nn.Module):\n",
    "    def __init__(self, num_actions, input_channels=4, num_scalars=9):\n",
    "        super().__init__()\n",
    "        self.cnn = MediumCNN(input_channels)\n",
    "        self.attention = CBAM(128)\n",
    "        self.scalar_network = ScalarNetwork(num_scalars)\n",
    "        self.actor = nn.Sequential(nn.Linear(512+64, 512), nn.ReLU(), nn.Linear(512, num_actions))\n",
    "        self.critic = nn.Sequential(nn.Linear(512+64, 512), nn.ReLU(), nn.Linear(512, 1))\n",
    "\n",
    "    def get_action(self, obs):\n",
    "        pov = obs['pov']\n",
    "        conv = self.cnn.conv(pov if pov.max() <= 1.0 else pov.float()/255.0)\n",
    "        attn = self.attention(conv)\n",
    "        cnn_feat = self.cnn.fc(attn.view(attn.size(0), -1))\n",
    "        \n",
    "        scalars = torch.stack([obs[k].view(-1) for k in [\n",
    "            'time_left', 'yaw', 'pitch', 'place_table_safe', 'inv_logs',\n",
    "            'inv_planks', 'inv_sticks', 'inv_table', 'inv_axe']], dim=1)\n",
    "        scalar_feat = self.scalar_network(scalars)\n",
    "        \n",
    "        feat = torch.cat([cnn_feat, scalar_feat], dim=1)\n",
    "        logits = self.actor(feat)\n",
    "        return torch.argmax(logits, dim=-1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2089306-f70a-4c85-a347-9086539fed19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ LAUNCHING MINECRAFT... Please wait 1-2 minutes.\n",
      "Using device: cpu\n",
      "✓ Model loaded successfully.\n",
      "Creating environment pipeline...\n",
      "Resetting environment (this takes about 45-60 seconds)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "/Users/brandon/Documents/envs/minerl-env/lib/python3.9/runpy.py:127: RuntimeWarning: 'minerl.utils.process_watcher' found in sys.modules after import of package 'minerl.utils', but prior to execution of 'minerl.utils.process_watcher'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "❌ CRASH DETECTED.\n",
      "Error details: /Users/brandon/Documents/envs/minerl-env/lib/python3.9/site-packages/minerl/env/../MCP-Reborn\n",
      "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
      "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
      "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
      "[19:42:23] [Render thread/INFO]: Environment: authHost='https://authserver.mojang.com', accountsHost='https://api.mojang.com', sessionHost='https://sessionserver.mojang.com', servicesHost='https://api.minecraftservices.com', name='PROD'\n",
      "[19:42:24] [Render thread/INFO]: Setting user: Player97\n",
      "[19:42:24] [Render thread/INFO]: [STDERR]: [LWJGL] Failed to load a library. Possible solutions:\n",
      "\ta) Add the directory that contains the shared library to -Djava.library.path or -Dorg.lwjgl.librarypath.\n",
      "\tb) Add the JAR that contains the shared library to the classpath.\n",
      "[19:42:24] [Render thread/INFO]: [STDERR]: [LWJGL] Enable debug mode with -Dorg.lwjgl.util.Debug=true for better diagnostics.\n",
      "[19:42:24] [Render thread/INFO]: [STDERR]: [LWJGL] Enable the SharedLibraryLoader debug mode with -Dorg.lwjgl.util.DebugLoader=true for better diagnostics.\n",
      "---- Minecraft Crash Report ----\n",
      "// Would you like a cupcake?\n",
      "\n",
      "Time: 12/12/25, 7:42 PM\n",
      "Description: Initializing game\n",
      "\n",
      "java.lang.ExceptionInInitializerError\n",
      "\tat net.minecraft.client.GameSettings.<init>(GameSettings.java:145)\n",
      "\tat net.minecraft.client.Minecraft.<init>(Minecraft.java:396)\n",
      "\tat net.minecraft.client.main.Main.main(Main.java:154)\n",
      "Caused by: java.lang.RuntimeException: java.lang.UnsatisfiedLinkError: Failed to locate library: liblwjgl.dylib\n",
      "\tat net.minecraft.client.util.InputMappings.<clinit>(InputMappings.java:104)\n",
      "\t... 3 more\n",
      "Caused by: java.lang.UnsatisfiedLinkError: Failed to locate library: liblwjgl.dylib\n",
      "\tat org.lwjgl.system.Library.loadSystem(Library.java:164)\n",
      "\tat org.lwjgl.system.Library.loadSystem(Library.java:63)\n",
      "\tat org.lwjgl.system.Library.<clinit>(Library.java:51)\n",
      "\tat org.lwjgl.glfw.GLFW.<clinit>(GLFW.java:30)\n",
      "\tat java.base/jdk.internal.misc.Unsafe.ensureClassInitialized0(Native Method)\n",
      "\tat java.base/jdk.internal.misc.Unsafe.ensureClassInitialized(Unsafe.java:1155)\n",
      "\tat java.base/java.lang.invoke.DirectMethodHandle$EnsureInitialized.computeValue(DirectMethodHandle.java:377)\n",
      "\tat java.base/java.lang.invoke.DirectMethodHandle$EnsureInitialized.computeValue(DirectMethodHandle.java:374)\n",
      "\tat java.base/java.lang.ClassValue.getFromHashMap(ClassValue.java:228)\n",
      "\tat java.base/java.lang.ClassValue.getFromBackup(ClassValue.java:210)\n",
      "\tat java.base/java.lang.ClassValue.get(ClassValue.java:116)\n",
      "\tat java.base/java.lang.invoke.DirectMethodHandle.checkInitialized(DirectMethodHandle.java:400)\n",
      "\tat java.base/java.lang.invoke.DirectMethodHandle.ensureInitialized(DirectMethodHandle.java:388)\n",
      "\tat java.base/java.lang.invoke.DirectMethodHandle.ensureInitialized(DirectMethodHandle.java:422)\n",
      "\tat net.minecraft.client.util.InputMappings.<clinit>(InputMappings.java:101)\n",
      "\t... 3 more\n",
      "\n",
      "\n",
      "A detailed walkthrough of the error, its code path and all known details is as follows:\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "-- Head --\n",
      "Thread: Render thread\n",
      "Stacktrace:\n",
      "\tat net.minecraft.client.GameSettings.<init>(GameSettings.java:145)\n",
      "\tat net.minecraft.client.Minecraft.<init>(Minecraft.java:396)\n",
      "\n",
      "-- Initialization --\n",
      "Details:\n",
      "Stacktrace:\n",
      "\tat net.minecraft.client.main.Main.main(Main.java:154)\n",
      "\n",
      "-- System Details --\n",
      "Details:\n",
      "\tMinecraft Version: 1.16.5\n",
      "\tMinecraft Version ID: 1.16.5\n",
      "\tOperating System: Mac OS X (aarch64) version 15.6.1\n",
      "\tJava Version: 17.0.10, Oracle Corporation\n",
      "\tJava VM Version: Java HotSpot(TM) 64-Bit Server VM (mixed mode, sharing), Oracle Corporation\n",
      "\tMemory: 416111040 bytes (396 MB) / 1251999744 bytes (1194 MB) up to 4294967296 bytes (4096 MB)\n",
      "\tCPUs: 8\n",
      "\tJVM Flags: 1 total; -Xmx4G\n",
      "\tLaunched Version: ~~NULL~~\n",
      "\tBackend library: LWJGL version 3.3.1 SNAPSHOT\n",
      "\tBackend API: ~~ERROR~~ NoClassDefFoundError: Could not initialize class org.lwjgl.glfw.GLFW\n",
      "\tGL Caps: \n",
      "\tUsing VBOs: Yes\n",
      "\tIs Modded: Very likely; Jar signature invalidated\n",
      "\tType: Client (map_client.txt)\n",
      "\tCPU: <unknown>\n",
      "#@!@# Game crashed! Crash report saved to: #@!@# /Users/brandon/Documents/envs/minerl-env/lib/python3.9/site-packages/minerl/MCP-Reborn/./crash-reports/crash-2025-12-12_19.42.24-client.txt\n",
      "\n",
      "\n",
      "Minecraft process finished unexpectedly. There was an error with Malmo.\n",
      "Tip: If you see 'address already in use', restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "print(\"LAUNCHING MINECRAFT... Please wait 1-2 minutes.\")\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "# --- CRITICAL MAC FIXES ---\n",
    "# Prevents a common hanging issue on Mac\n",
    "os.environ['MINERL_MOCK_FILE_OPEN'] = 'true'\n",
    "# Forces the game to render without a window (prevents graphics driver crashes)\n",
    "os.environ['MINERL_HEADLESS'] = 'true' \n",
    "# --------------------------\n",
    "\n",
    "# 1. Load Configuration\n",
    "with open(\"config.yaml\", \"r\") as f: \n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. Initialize Network\n",
    "# Matching config enabled_actions length\n",
    "enabled_actions = config['action_space']['enabled_actions'] \n",
    "model = ActorCriticNetwork(num_actions=len(enabled_actions)).to(device)\n",
    "\n",
    "# 3. Load Weights\n",
    "try:\n",
    "    checkpoint = torch.load(\"checkpoint_ppo_ep3000.pt\", map_location=device)\n",
    "    if 'network' in checkpoint: \n",
    "        state_dict = checkpoint['network']['policy_state_dict']\n",
    "    else: \n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    # Strict=False allows us to load partial weights if the architecture isn't perfect\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model.eval()\n",
    "    print(\"✓ Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "\n",
    "# 4. Create Environment Pipeline\n",
    "print(\"Creating environment pipeline...\")\n",
    "try:\n",
    "    # We set a distinct port (5555) to avoid conflicts with previous runs\n",
    "    base_env = gym.make('MineRLcustom_treechop-v0')\n",
    "    \n",
    "    env_vision = StackAndProcessWrapper(base_env)\n",
    "    env_hold = HoldAttackWrapper(env_vision, hold_steps=35, lock_aim=True, pass_through_move=False)\n",
    "    env_obs = ObservationWrapper(env_hold)\n",
    "    env = ConfigurableActionWrapper(env_obs, enabled_actions=enabled_actions)\n",
    "\n",
    "    # 5. Run Loop\n",
    "    print(\"Resetting environment (this takes about 45-60 seconds)...\")\n",
    "    obs = env.reset()\n",
    "    print(\"✓ Environment reset successful! Running inference loop...\")\n",
    "    \n",
    "    total_reward = 0\n",
    "    \n",
    "    # Run for 500 steps (approx 2 minutes of gameplay)\n",
    "    for i in range(10):\n",
    "        # Prepare Tensors\n",
    "        state = {k: torch.from_numpy(v).unsqueeze(0).to(device) for k, v in obs.items() if isinstance(v, np.ndarray)}\n",
    "        # Ensure POV is float tensor\n",
    "        if 'pov' not in state: \n",
    "            state['pov'] = torch.from_numpy(obs['pov']).unsqueeze(0).float().to(device)\n",
    "\n",
    "        # Get Action from Model\n",
    "        with torch.no_grad():\n",
    "            action_idx = model.get_action(state)\n",
    "        \n",
    "        # Step Environment\n",
    "        obs, reward, done, info = env.step(action_idx)\n",
    "        total_reward += reward\n",
    "        \n",
    "        # --- VISUALIZATION (Since Headless Mode hides the window) ---\n",
    "        if i % 20 == 0:\n",
    "            clear_output(wait=True) # Clear previous image to make an animation\n",
    "            \n",
    "            # Get the most recent frame (84x84 grayscale)\n",
    "            frame = obs['pov'][-1] \n",
    "            \n",
    "            plt.figure(figsize=(4, 4))\n",
    "            plt.imshow(frame, cmap='gray', vmin=0, vmax=255)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Step: {i} | Action: {action_idx} | Reward: {total_reward:.2f}\")\n",
    "            plt.show()\n",
    "            print(f\"Processing Step {i}...\") # Print to confirm loop is alive\n",
    "        # -------------------------------------------------------------\n",
    "        \n",
    "        if done:\n",
    "            print(\"Episode finished.\")\n",
    "            break\n",
    "            \n",
    "    env.close()\n",
    "    print(\"Demo complete.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\n❌ CRASH DETECTED.\")\n",
    "    print(f\"Error details: {e}\")\n",
    "    print(\"Tip: If you see 'address already in use', restart the kernel.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
